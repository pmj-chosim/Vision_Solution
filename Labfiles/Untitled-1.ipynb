{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 이미지분석\n",
    "2. custom vision- clssification\n",
    "3. face \n",
    "4. OCR\n",
    "5. Video Indexer\n",
    "\n",
    "# Azure AI Vision 솔루션"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* .NET 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Azure.AI.Vision.Common, 0.11.0</span></li><li><span>Azure.AI.Vision.Core, 0.10.0-beta.1</span></li><li><span>Azure.AI.Vision.ImageAnalysis, 1.0.0-beta.2</span></li><li><span>Microsoft.Azure.CognitiveServices.Language.LUIS.Runtime, 3.0.0</span></li><li><span>Microsoft.Azure.CognitiveServices.Language.TextAnalytics, 3.0.0</span></li><li><span>Microsoft.Azure.CognitiveServices.Vision.ComputerVision, 7.0.1</span></li><li><span>Microsoft.Azure.CognitiveServices.Vision.Face, 2.8.0-preview.3</span></li><li><span>Microsoft.Extensions.Configuration.Json, 3.1.3</span></li><li><span>System.Drawing.Common, 4.7.0</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "Error",
     "evalue": "C:\\Users\\parkm\\.packagemanagement\\nuget\\Projects\\39632--5860451e-8234-4506-a31c-42b270b4284d\\Project.fsproj : error NU1101: Microsoft.Azure.CognitiveServices.Authentications 패키지를 찾을 수 없습니다. 원본에 ID가 C:\\Program Files\\dotnet\\library-packs, C:\\Program Files\\dotnet\\sdk\\8.0.205\\FSharp\\library-packs, nuget.org인 패키지가 없습니다.\r\nC:\\Users\\parkm\\.packagemanagement\\nuget\\Projects\\39632--5860451e-8234-4506-a31c-42b270b4284d\\Project.fsproj : warning NU1902: 'Microsoft.Rest.ClientRuntime' 2.3.20 패키지에 알려진 보통 심각도 취약성인 https://github.com/advisories/GHSA-whph-446h-6m9v이(가) 있습니다.\r\nC:\\Users\\parkm\\.packagemanagement\\nuget\\Projects\\39632--5860451e-8234-4506-a31c-42b270b4284d\\Project.fsproj : warning NU1903: 'Newtonsoft.Json' 10.0.3 패키지에 알려진 높은 심각도 취약성인 https://github.com/advisories/GHSA-5crp-9r3c-p9vr이(가) 있습니다.\r\nC:\\Users\\parkm\\.packagemanagement\\nuget\\Projects\\39632--5860451e-8234-4506-a31c-42b270b4284d\\Project.fsproj : warning NU1904: 'System.Drawing.Common' 4.7.0 패키지에 알려진 위험 심각도 취약성인 https://github.com/advisories/GHSA-rxg9-xrhp-64gj이(가) 있습니다.\r\nC:\\Users\\parkm\\.packagemanagement\\nuget\\Projects\\39632--5860451e-8234-4506-a31c-42b270b4284d\\Project.fsproj : warning NU1605: 3.3.19에서 3.3.18(으)로 다운그레이드된 패키지 Microsoft.Rest.ClientRuntime.Azure을(를) 발견했습니다. 프로젝트에서 패키지를 직접 참조하여 다른 버전을 선택하세요. \r\nC:\\Users\\parkm\\.packagemanagement\\nuget\\Projects\\39632--5860451e-8234-4506-a31c-42b270b4284d\\Project.fsproj : warning NU1605:  Project -> Microsoft.Azure.CognitiveServices.Language.TextAnalytics 3.0.0 -> Microsoft.Rest.ClientRuntime.Azure (>= 3.3.19 && < 4.0.0) \r\nC:\\Users\\parkm\\.packagemanagement\\nuget\\Projects\\39632--5860451e-8234-4506-a31c-42b270b4284d\\Project.fsproj : warning NU1605:  Project -> Microsoft.Rest.ClientRuntime.Azure (>= 3.3.18)",
     "output_type": "error",
     "traceback": [
      "C:\\Users\\parkm\\.packagemanagement\\nuget\\Projects\\39632--5860451e-8234-4506-a31c-42b270b4284d\\Project.fsproj : error NU1101: Microsoft.Azure.CognitiveServices.Authentications 패키지를 찾을 수 없습니다. 원본에 ID가 C:\\Program Files\\dotnet\\library-packs, C:\\Program Files\\dotnet\\sdk\\8.0.205\\FSharp\\library-packs, nuget.org인 패키지가 없습니다.\r\n",
      "C:\\Users\\parkm\\.packagemanagement\\nuget\\Projects\\39632--5860451e-8234-4506-a31c-42b270b4284d\\Project.fsproj : warning NU1902: 'Microsoft.Rest.ClientRuntime' 2.3.20 패키지에 알려진 보통 심각도 취약성인 https://github.com/advisories/GHSA-whph-446h-6m9v이(가) 있습니다.\r\n",
      "C:\\Users\\parkm\\.packagemanagement\\nuget\\Projects\\39632--5860451e-8234-4506-a31c-42b270b4284d\\Project.fsproj : warning NU1903: 'Newtonsoft.Json' 10.0.3 패키지에 알려진 높은 심각도 취약성인 https://github.com/advisories/GHSA-5crp-9r3c-p9vr이(가) 있습니다.\r\n",
      "C:\\Users\\parkm\\.packagemanagement\\nuget\\Projects\\39632--5860451e-8234-4506-a31c-42b270b4284d\\Project.fsproj : warning NU1904: 'System.Drawing.Common' 4.7.0 패키지에 알려진 위험 심각도 취약성인 https://github.com/advisories/GHSA-rxg9-xrhp-64gj이(가) 있습니다.\r\n",
      "C:\\Users\\parkm\\.packagemanagement\\nuget\\Projects\\39632--5860451e-8234-4506-a31c-42b270b4284d\\Project.fsproj : warning NU1605: 3.3.19에서 3.3.18(으)로 다운그레이드된 패키지 Microsoft.Rest.ClientRuntime.Azure을(를) 발견했습니다. 프로젝트에서 패키지를 직접 참조하여 다른 버전을 선택하세요. \r\n",
      "C:\\Users\\parkm\\.packagemanagement\\nuget\\Projects\\39632--5860451e-8234-4506-a31c-42b270b4284d\\Project.fsproj : warning NU1605:  Project -> Microsoft.Azure.CognitiveServices.Language.TextAnalytics 3.0.0 -> Microsoft.Rest.ClientRuntime.Azure (>= 3.3.19 && < 4.0.0) \r\n",
      "C:\\Users\\parkm\\.packagemanagement\\nuget\\Projects\\39632--5860451e-8234-4506-a31c-42b270b4284d\\Project.fsproj : warning NU1605:  Project -> Microsoft.Rest.ClientRuntime.Azure (>= 3.3.18)"
     ]
    }
   ],
   "source": [
    "//#r \"nuget: Azure.AI.Vision.ImageAnalysis, 1.0.0-beta.1\"\n",
    "#r \"nuget: Microsoft.Extensions.Configuration.Json, 3.1.3\"\n",
    "#r \"nuget: System.Drawing.Common, 4.7.0\"\n",
    "#r \"nuget: Microsoft.Azure.CognitiveServices.Vision.ComputerVision\"\n",
    "#r \"nuget: Azure.AI.Vision.Common\"\n",
    "#r \"nuget: Microsoft.Azure.CognitiveServices.Vision.Face, 2.8.0-preview.3\"\n",
    "#r \"nuget: Azure.AI.Vision.Core, 0.10.0-beta.1\"\n",
    "#r \"nuget: Azure.AI.Vision.ImageAnalysis, 1.0.0-beta.2\"\n",
    "#r \"nuget: Microsoft.Azure.CognitiveServices.Language.LUIS.Runtime, 3.0.0\"\n",
    "#r \"nuget: Microsoft.Azure.CognitiveServices.Language.TextAnalytics, 3.0.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* namespace 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using System;\n",
    "using System.IO;\n",
    "using System.Net.Http;\n",
    "using System.Net.Http.Headers;\n",
    "using System.Text;\n",
    "using System.Text.Json;\n",
    "using System.Threading.Tasks;\n",
    "using System.Drawing;\n",
    "using Microsoft.Extensions.Configuration;\n",
    "using Azure;\n",
    "using Azure.AI.Vision.ImageAnalysis;\n",
    "using Azure.AI.Vision.Common;\n",
    "using Azure.AI.Vision;\n",
    "using Microsoft.Azure.CognitiveServices.Vision.Face;\n",
    "using Microsoft.Azure.CognitiveServices.Vision.Face.Models;\n",
    "using Microsoft.Azure.CognitiveServices.Vision.ComputerVision;\n",
    "using Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models;\n",
    "using Azure.AI.Vision.Core.Options;\n",
    "using Azure.AI.Vision.Core.Input;\n",
    "using System.Linq;\n",
    "using System.Collections.Generic;\n",
    "using System.Threading;\n",
    "using Microsoft.Azure.CognitiveServices.Language.LUIS.Runtime;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 이미지 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "public class image_analysis\n",
    "    {\n",
    "\n",
    "        public static async Task Main(string[] args)\n",
    "        {\n",
    "            try\n",
    "            {\n",
    "                // Get config settings from AppSettings\n",
    "                String address_1=\"C:\\\\Users\\\\parkm\\\\Desktop\\\\Vision\\\\mslearn-ai-vision\\\\Labfiles\\\\01-analyze-images\\\\C-Sharp\\\\image-analysis\\\\\";\n",
    "                \n",
    "                IConfigurationBuilder builder = new ConfigurationBuilder().AddJsonFile(address_1+\"appsettings.json\");\n",
    "                IConfigurationRoot configuration = builder.Build();\n",
    "                string aiSvcEndpoint = configuration[\"AIServicesEndpoint\"];\n",
    "                string aiSvcKey = configuration[\"AIServicesKey\"];\n",
    "\n",
    "                // Get image\n",
    "                string imageFile = address_1+\"images/street.jpg\";\n",
    "                if (args.Length > 0)\n",
    "                {\n",
    "                    imageFile = args[0];\n",
    "                }\n",
    "\n",
    "                // Authenticate Azure AI Vision client\n",
    "                var client = new ImageAnalysisClient(new Uri(aiSvcEndpoint), new AzureKeyCredential(aiSvcKey));\n",
    "                \n",
    "                // Analyze image\n",
    "                AnalyzeImage(imageFile, client);\n",
    "\n",
    "                // Remove the background or generate a foreground matte from the image\n",
    "                await BackgroundForeground(imageFile, aiSvcEndpoint, aiSvcKey);\n",
    "\n",
    "            }\n",
    "            catch (Exception ex)\n",
    "            {\n",
    "                Console.WriteLine(ex.Message);\n",
    "            }\n",
    "        }\n",
    "\n",
    "        static void AnalyzeImage(string imageFile, ImageAnalysisClient client)\n",
    "        {\n",
    "            Console.WriteLine($\"\\nAnalyzing {imageFile} \\n\");\n",
    "\n",
    "            // Use a file stream to pass the image data to the analyze call\n",
    "            using FileStream stream = new FileStream(imageFile,\n",
    "                                                     FileMode.Open);\n",
    "\n",
    "            // Get result with specified features to be retrieved\n",
    "            ImageAnalysisResult result = client.Analyze(\n",
    "                BinaryData.FromStream(stream),\n",
    "                VisualFeatures.Caption | \n",
    "                VisualFeatures.DenseCaptions |\n",
    "                VisualFeatures.Objects |\n",
    "                VisualFeatures.Tags |\n",
    "                VisualFeatures.People);\n",
    "                        \n",
    "            // Display analysis results\n",
    "            // Get image captions\n",
    "            if (result.Caption.Text != null)\n",
    "            {\n",
    "                Console.WriteLine(\" Caption:\");\n",
    "                Console.WriteLine($\"   \\\"{result.Caption.Text}\\\", Confidence {result.Caption.Confidence:0.00}\\n\");\n",
    "            }\n",
    "\n",
    "            // Get image dense captions\n",
    "            Console.WriteLine(\" Dense Captions:\");\n",
    "            foreach (DenseCaption denseCaption in result.DenseCaptions.Values)\n",
    "            {\n",
    "                Console.WriteLine($\"   Caption: '{denseCaption.Text}', Confidence: {denseCaption.Confidence:0.00}\");\n",
    "            }\n",
    "\n",
    "        }\n",
    "        static async Task BackgroundForeground(string imageFile, string endpoint, string key)\n",
    "        {\n",
    "            // Remove the background from the image or generate a foreground matte\n",
    "            Console.WriteLine($\" Background removal:\");\n",
    "            // Define the API version and mode\n",
    "            string apiVersion = \"2023-02-01-preview\";\n",
    "            string mode = \"backgroundRemoval\"; // Can be \"foregroundMatting\" or \"backgroundRemoval\"\n",
    "\n",
    "            string url = $\"computervision/imageanalysis:segment?api-version={apiVersion}&mode={mode}\";\n",
    "\n",
    "            // Make the REST call\n",
    "            using (var client = new HttpClient())\n",
    "            {\n",
    "                var contentType = new MediaTypeWithQualityHeaderValue(\"application/json\");\n",
    "                client.BaseAddress = new Uri(endpoint);\n",
    "                client.DefaultRequestHeaders.Accept.Add(contentType);\n",
    "                client.DefaultRequestHeaders.Add(\"Ocp-Apim-Subscription-Key\", key);\n",
    "\n",
    "                var data = new\n",
    "                {\n",
    "                    url = $\"https://github.com/MicrosoftLearning/mslearn-ai-vision/blob/main/Labfiles/01-analyze-images/Python/image-analysis/images/street.jpg?raw=true\"\n",
    "                };\n",
    "\n",
    "                var jsonData = JsonSerializer.Serialize(data);\n",
    "                var contentData = new StringContent(jsonData, Encoding.UTF8, contentType);\n",
    "                var response = await client.PostAsync(url, contentData);\n",
    "\n",
    "                if (response.IsSuccessStatusCode) {\n",
    "                    File.WriteAllBytes(\"background.png\", response.Content.ReadAsByteArrayAsync().Result);\n",
    "                    Console.WriteLine(\"  Results saved in background.png\\n\");\n",
    "                }\n",
    "                else\n",
    "                {\n",
    "                    Console.WriteLine($\"API error: {response.ReasonPhrase} - Check your body url, key, and endpoint.\");\n",
    "                }\n",
    "            }\n",
    "            \n",
    "        }\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing C:\\Users\\parkm\\Desktop\\Vision\\mslearn-ai-vision\\Labfiles\\01-analyze-images\\C-Sharp\\image-analysis\\images/street.jpg \n",
      "\n",
      " Caption:\n",
      "   \"a man walking a dog on a leash on a street\", Confidence 0.82\n",
      "\n",
      " Dense Captions:\n",
      "   Caption: 'a man walking a dog on a leash on a street', Confidence: 0.82\n",
      "   Caption: 'a man walking on a street', Confidence: 0.69\n",
      "   Caption: 'a yellow car on the street', Confidence: 0.78\n",
      "   Caption: 'a black dog walking on the street', Confidence: 0.75\n",
      "   Caption: 'a blurry image of a blue car', Confidence: 0.82\n",
      "   Caption: 'a yellow taxi cab on the street', Confidence: 0.72\n",
      " Background removal:\n",
      "  Results saved in background.png\n",
      "\n"
     ]
    }
   ],
   "source": [
    "await image_analysis.Main(new string[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.얼굴 감지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Computer Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "(42,17): error CS0117: 'ImageAnalysisOptions'에는 'Features'에 대한 정의가 포함되어 있지 않습니다.\r\n(43,22): error CS0103: 'ImageAnalysisFeature' 이름이 현재 컨텍스트에 없습니다.\r\n(49,38): error CS0246: 'ImageAnalyzer' 형식 또는 네임스페이스 이름을 찾을 수 없습니다. using 지시문 또는 어셈블리 참조가 있는지 확인하세요.\r\n(53,34): error CS0103: 'ImageAnalysisResultReason' 이름이 현재 컨텍스트에 없습니다.\r\n(90,36): error CS0103: 'ImageAnalysisErrorDetails' 이름이 현재 컨텍스트에 없습니다.",
     "output_type": "error",
     "traceback": [
      "(42,17): error CS0117: 'ImageAnalysisOptions'에는 'Features'에 대한 정의가 포함되어 있지 않습니다.\r\n",
      "(43,22): error CS0103: 'ImageAnalysisFeature' 이름이 현재 컨텍스트에 없습니다.\r\n",
      "(49,38): error CS0246: 'ImageAnalyzer' 형식 또는 네임스페이스 이름을 찾을 수 없습니다. using 지시문 또는 어셈블리 참조가 있는지 확인하세요.\r\n",
      "(53,34): error CS0103: 'ImageAnalysisResultReason' 이름이 현재 컨텍스트에 없습니다.\r\n",
      "(90,36): error CS0103: 'ImageAnalysisErrorDetails' 이름이 현재 컨텍스트에 없습니다."
     ]
    }
   ],
   "source": [
    "public class detect_people\n",
    "{\n",
    "        public static void Main(string[] args)\n",
    "        {\n",
    "            try\n",
    "            {\n",
    "                // Get config settings from AppSettings\n",
    "                String address_2=\"C:/Users/parkm/Desktop/Vision/mslearn-ai-vision/Labfiles/04-face/C-Sharp/computer-vision/\";\n",
    "                string aiSvcEndpoint = \"https://fruit-train.cognitiveservices.azure.com/\";\n",
    "                string aiSvcKey = \"68309624561e4968~~\";\n",
    "\n",
    "                // Get image\n",
    "                string imageFile = address_2+\"images/people.jpg\";\n",
    "                if (args.Length > 0)\n",
    "                {\n",
    "                    imageFile = args[0];\n",
    "                }\n",
    "\n",
    "                // Authenticate Azure AI Vision client\n",
    "                var cvClient = new VisionServiceOptions(\n",
    "                aiSvcEndpoint,\n",
    "                new AzureKeyCredential(aiSvcKey));\n",
    "\n",
    "                \n",
    "                // Analyze image\n",
    "                AnalyzeImage(imageFile, cvClient);\n",
    "\n",
    "            }\n",
    "            catch (Exception ex)\n",
    "            {\n",
    "                Console.WriteLine(ex.Message);\n",
    "            }\n",
    "        }\n",
    "\n",
    "        static void AnalyzeImage(string imageFile, VisionServiceOptions serviceOptions)\n",
    "        {\n",
    "            Console.WriteLine($\"\\nAnalyzing {imageFile} \\n\");\n",
    "\n",
    "            var analysisOptions = new ImageAnalysisOptions()\n",
    "            {\n",
    "                 // Specify features to be retrieved (PEOPLE)\n",
    "                Features =\n",
    "                     ImageAnalysisFeature.People\n",
    "            };\n",
    "\n",
    "            // Get image analysis\n",
    "            using var imageSource = VisionSource.FromFile(imageFile);\n",
    "                \n",
    "            using var analyzer = new ImageAnalyzer(serviceOptions, imageSource, analysisOptions);\n",
    "                \n",
    "            var result = analyzer.Analyze();\n",
    "                \n",
    "            if (result.Reason == ImageAnalysisResultReason.Analyzed)\n",
    "            {\n",
    "                // Get people in the image\n",
    "                if (result.People != null)\n",
    "                {\n",
    "                    Console.WriteLine($\" People:\");\n",
    "                    \n",
    "                    // Prepare image for drawing\n",
    "                    System.Drawing.Image image = System.Drawing.Image.FromFile(imageFile);\n",
    "                    Graphics graphics = Graphics.FromImage(image);\n",
    "                    Pen pen = new Pen(Color.Cyan, 3);\n",
    "                    Font font = new Font(\"Arial\", 16);\n",
    "                    SolidBrush brush = new SolidBrush(Color.WhiteSmoke);\n",
    "                    \n",
    "                    foreach (var person in result.People)\n",
    "                    {\n",
    "                        // Draw object bounding box if confidence > 50%\n",
    "                        if (person.Confidence > 0.5)\n",
    "                        {\n",
    "                            // Draw object bounding box\n",
    "                            var r = person.BoundingBox;\n",
    "                            Rectangle rect = new Rectangle(r.X, r.Y, r.Width, r.Height);\n",
    "                            graphics.DrawRectangle(pen, rect);\n",
    "                    \n",
    "                            // Return the confidence of the person detected\n",
    "                            Console.WriteLine($\"   Bounding box {person.BoundingBox}, Confidence {person.Confidence:0.0000}\");\n",
    "                        }\n",
    "                    }\n",
    "                    \n",
    "                    // Save annotated image\n",
    "                    String output_file = \"detected_people.jpg\";\n",
    "                    image.Save(output_file);\n",
    "                    Console.WriteLine(\"  Results saved in \" + output_file + \"\\n\");\n",
    "                }\n",
    "            }\n",
    "            else\n",
    "            {\n",
    "                var errorDetails = ImageAnalysisErrorDetails.FromResult(result);\n",
    "                Console.WriteLine(\" Analysis failed.\");\n",
    "                Console.WriteLine($\"   Error reason : {errorDetails.Reason}\");\n",
    "                Console.WriteLine($\"   Error code : {errorDetails.ErrorCode}\");\n",
    "                Console.WriteLine($\"   Error message: {errorDetails.Message}\\n\");\n",
    "            }\n",
    " \n",
    "        }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "DetectPeople.Main(new string[] {});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Face API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "(14,39): error CS0104: 'ApiKeyServiceClientCredentials'은(는) 'Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ApiKeyServiceClientCredentials' 및 'Microsoft.Azure.CognitiveServices.Vision.Face.ApiKeyServiceClientCredentials' 사이에 모호한 참조입니다.\r\n(52,115): error CS1503: 3 인수: 'System.Collections.Generic.List<Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.VisualFeatureTypes?>'에서 'System.Collections.Generic.IList<Microsoft.Azure.CognitiveServices.Vision.Face.Models.FaceAttributeType>'(으)로 변환할 수 없습니다.\r\n(54,21): error CS0019: '>' 연산자는 '메서드 그룹' 및 'int' 형식의 피연산자에 적용할 수 없습니다.\r\n(56,42): error CS1503: 1 인수: '메서드 그룹'에서 'scoped System.ReadOnlySpan<char>'(으)로 변환할 수 없습니다.",
     "output_type": "error",
     "traceback": [
      "(14,39): error CS0104: 'ApiKeyServiceClientCredentials'은(는) 'Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ApiKeyServiceClientCredentials' 및 'Microsoft.Azure.CognitiveServices.Vision.Face.ApiKeyServiceClientCredentials' 사이에 모호한 참조입니다.\r\n",
      "(52,115): error CS1503: 3 인수: 'System.Collections.Generic.List<Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.VisualFeatureTypes?>'에서 'System.Collections.Generic.IList<Microsoft.Azure.CognitiveServices.Vision.Face.Models.FaceAttributeType>'(으)로 변환할 수 없습니다.\r\n",
      "(54,21): error CS0019: '>' 연산자는 '메서드 그룹' 및 'int' 형식의 피연산자에 적용할 수 없습니다.\r\n",
      "(56,42): error CS1503: 1 인수: '메서드 그룹'에서 'scoped System.ReadOnlySpan<char>'(으)로 변환할 수 없습니다."
     ]
    }
   ],
   "source": [
    "public class analyze_faces\n",
    "{\n",
    "        private static FaceClient faceClient;\n",
    "        static async Task Main(string[] args)\n",
    "        {\n",
    "            try\n",
    "            {\n",
    "                // Get config settings from AppSettings\n",
    "\n",
    "                string cogSvcEndpoint = \"ttps://fruit-train.cognitiveservices.azure.com/\";\n",
    "                string cogSvcKey = \"68309624561e4968~~\";\n",
    "\n",
    "                // Authenticate Face client\n",
    "                var credentials = new ApiKeyServiceClientCredentials(cogSvcKey);\n",
    "                faceClient = new FaceClient(credentials)\n",
    "                {\n",
    "                    Endpoint = cogSvcEndpoint\n",
    "                };\n",
    "\n",
    "                // Menu for face functions\n",
    "                Console.WriteLine(\"1: Detect faces\\nAny other key to quit\");\n",
    "                Console.WriteLine(\"Enter a number:\");\n",
    "                string command = Console.ReadLine();\n",
    "                switch (command)\n",
    "                {\n",
    "                    case \"1\":\n",
    "                        await DetectFaces(\"images/people.jpg\");\n",
    "                        break;\n",
    "                    default:\n",
    "                        break;\n",
    "                }\n",
    "            }\n",
    "            catch (Exception ex)\n",
    "            {\n",
    "                Console.WriteLine(ex.Message);\n",
    "            }\n",
    "        }\n",
    "\n",
    "        static async Task DetectFaces(string imageFile)\n",
    "        {\n",
    "            Console.WriteLine($\"Detecting faces in {imageFile}\");\n",
    "\n",
    "            // Specify facial features to be retrieved\n",
    "             List<VisualFeatureTypes?> features = new List<VisualFeatureTypes?>()\n",
    "            {\n",
    "                VisualFeatureTypes.Faces\n",
    "            };\n",
    "\n",
    "             // Get faces\n",
    "            using (var imageData = File.OpenRead(imageFile))\n",
    "            {    \n",
    "                var detected_faces = await faceClient.Face.DetectWithStreamAsync(imageData, returnFaceAttributes: features, returnFaceId: false);\n",
    "\n",
    "                if (detected_faces.Count > 0)\n",
    "                {\n",
    "                    Console.WriteLine($\"{detected_faces.Count} faces detected.\");\n",
    "\n",
    "                    // Prepare image for drawing\n",
    "                    Image image = Image.FromFile(imageFile);\n",
    "                    Graphics graphics = Graphics.FromImage(image);\n",
    "                    Pen pen = new Pen(Color.LightGreen, 3);\n",
    "                    Font font = new Font(\"Arial\", 4);\n",
    "                    SolidBrush brush = new SolidBrush(Color.Black);\n",
    "                    int faceCount=0;\n",
    "\n",
    "                    // Draw and annotate each face\n",
    "                    foreach (var face in detected_faces)\n",
    "                    {\n",
    "                        faceCount++;\n",
    "                        Console.WriteLine($\"\\nFace number {faceCount}\");\n",
    "                        \n",
    "                        // Get face properties\n",
    "                        Console.WriteLine($\" - Mouth Occluded: {face.FaceAttributes.Occlusion.MouthOccluded}\");\n",
    "                        Console.WriteLine($\" - Eye Occluded: {face.FaceAttributes.Occlusion.EyeOccluded}\");\n",
    "                        Console.WriteLine($\" - Blur: {face.FaceAttributes.Blur.BlurLevel}\");\n",
    "                        Console.WriteLine($\" - Glasses: {face.FaceAttributes.Glasses}\");\n",
    "\n",
    "                        // Draw and annotate face\n",
    "                        var r = face.FaceRectangle;\n",
    "                        Rectangle rect = new Rectangle(r.Left, r.Top, r.Width, r.Height);\n",
    "                        graphics.DrawRectangle(pen, rect);\n",
    "                        string annotation = $\"Face ID: {face.FaceId}\";\n",
    "                        graphics.DrawString(annotation,font,brush,r.Left, r.Top);\n",
    "                    }\n",
    "\n",
    "                    // Save annotated image\n",
    "                    String output_file = \"detected_faces.jpg\";\n",
    "                    image.Save(output_file);\n",
    "                    Console.WriteLine(\" Results saved in \" + output_file);   \n",
    "                }\n",
    "            }\n",
    " \n",
    " \n",
    "        }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    " public static String address_3=\"C:\\\\Users\\\\parkm\\\\Desktop\\\\Vision\\\\mslearn-ai-vision\\\\Labfiles\\\\05-ocr\\\\C-Sharp\\\\read-text\\\\images\\\\\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "public class read_text\n",
    "    {\n",
    "\n",
    "        public static void Main(string[] args)\n",
    "        {\n",
    "            try\n",
    "            {\n",
    "                // Get config settings from AppSettings\n",
    "                string aiSvcEndpoint = \"https://fruit-train.cognitiveservices.azure.com/\";\n",
    "                string aiSvcKey = \"68309624561e4~~\";\n",
    "\n",
    "                // Authenticate Azure AI Vision client\n",
    "                ImageAnalysisClient client = new ImageAnalysisClient(\n",
    "                new Uri(aiSvcEndpoint),\n",
    "                new AzureKeyCredential(aiSvcKey));\n",
    "\n",
    "                // Menu for text reading functions\n",
    "                Console.WriteLine(\"\\n1: Use Read API for image (Lincoln.jpg)\\n2: Read handwriting (Note.jpg)\\nAny other key to quit\\n\");\n",
    "                string imageFile;\n",
    "\n",
    "                switch (args[0])\n",
    "                {\n",
    "                    case \"1\":\n",
    "                        imageFile = address_3+\"Lincoln.jpg\";\n",
    "                        GetTextRead(imageFile, client);\n",
    "                        break;\n",
    "                    case \"2\":\n",
    "                        imageFile = address_3+\"Note.jpg\";\n",
    "                        GetTextRead(imageFile, client);\n",
    "                        break;\n",
    "                    default:\n",
    "                        break;\n",
    "                }\n",
    "\n",
    "            }\n",
    "            catch (Exception ex)\n",
    "            {\n",
    "                Console.WriteLine(ex.Message);\n",
    "            }\n",
    "        }\n",
    "\n",
    "        static void GetTextRead(string imageFile, ImageAnalysisClient client)\n",
    "        {\n",
    "            Console.WriteLine($\"\\nReading text from {imageFile} \\n\");\n",
    "\n",
    "            // Use a file stream to pass the image data to the analyze call\n",
    "            using FileStream stream = new FileStream(imageFile,\n",
    "                                                     FileMode.Open);\n",
    "\n",
    "            // Use Analyze image function to read text in image\n",
    "            ImageAnalysisResult result = client.Analyze(\n",
    "                BinaryData.FromStream(stream),\n",
    "                // Specify the features to be retrieved\n",
    "                VisualFeatures.Read);\n",
    "                \n",
    "            stream.Close();\n",
    "                \n",
    "            // Display analysis results\n",
    "            if (result.Read != null)\n",
    "            {\n",
    "                Console.WriteLine($\"Text:\");\n",
    "                \n",
    "                // Prepare image for drawing\n",
    "                System.Drawing.Image image = System.Drawing.Image.FromFile(imageFile);\n",
    "                Graphics graphics = Graphics.FromImage(image);\n",
    "                Pen pen = new Pen(Color.Cyan, 3);\n",
    "                    \n",
    "                foreach (var line in result.Read.Blocks.SelectMany(block => block.Lines))\n",
    "                {\n",
    "                     // Return the text detected in the image\n",
    "                    Console.WriteLine($\"   '{line.Text}'\");\n",
    "                        \n",
    "                    // Draw bounding box around line\n",
    "                    var drawLinePolygon = true;\n",
    "                        \n",
    "                    // Return the position bounding box around each line\n",
    "                    Console.WriteLine($\"   Bounding Polygon: [{string.Join(\" \", line.BoundingPolygon)}]\");   \n",
    "                        \n",
    "                   // Return each word detected in the image and the position bounding box around each word with the confidence level of each word\n",
    "                    foreach (DetectedTextWord word in line.Words)\n",
    "                    {\n",
    "                        Console.WriteLine($\"     Word: '{word.Text}', Confidence {word.Confidence:F4}, Bounding Polygon: [{string.Join(\" \", word.BoundingPolygon)}]\");\n",
    "                            \n",
    "                        // Draw word bounding polygon\n",
    "                        drawLinePolygon = false;\n",
    "                        var r = word.BoundingPolygon;\n",
    "                        \n",
    "                        Point[] polygonPoints = {\n",
    "                            new Point(r[0].X, r[0].Y),\n",
    "                            new Point(r[1].X, r[1].Y),\n",
    "                            new Point(r[2].X, r[2].Y),\n",
    "                            new Point(r[3].X, r[3].Y)\n",
    "                        };\n",
    "                        \n",
    "                        graphics.DrawPolygon(pen, polygonPoints);\n",
    "                    }\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                    // Draw line bounding polygon\n",
    "                    if (drawLinePolygon)\n",
    "                    {\n",
    "                        var r = line.BoundingPolygon;\n",
    "                        \n",
    "                        Point[] polygonPoints = {\n",
    "                            new Point(r[0].X, r[0].Y),\n",
    "                            new Point(r[1].X, r[1].Y),\n",
    "                            new Point(r[2].X, r[2].Y),\n",
    "                            new Point(r[3].X, r[3].Y)\n",
    "                        };\n",
    "                        \n",
    "                        graphics.DrawPolygon(pen, polygonPoints);\n",
    "                    }\n",
    "                                    \n",
    "                \n",
    "                }\n",
    "                        \n",
    "                // Save image\n",
    "                String output_file = \"text.jpg\";\n",
    "                image.Save(output_file);\n",
    "                Console.WriteLine(\"\\nResults saved in \" + output_file + \"\\n\");   \n",
    "            }\n",
    "            \n",
    "    \n",
    "        }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1: Use Read API for image (Lincoln.jpg)\n",
      "2: Read handwriting (Note.jpg)\n",
      "Any other key to quit\n",
      "\n",
      "\n",
      "Reading text from C:\\Users\\parkm\\Desktop\\Vision\\mslearn-ai-vision\\Labfiles\\05-ocr\\C-Sharp\\read-text\\images\\Note.jpg \n",
      "\n",
      "Text:\n",
      "   'Shopping List'\n",
      "   Bounding Polygon: [(231, 141) (693, 147) (691, 245) (230, 240)]\n",
      "     Word: 'Shopping', Confidence 0.9630, Bounding Polygon: [(240, 141) (535, 149) (531, 245) (234, 234)]\n",
      "     Word: 'List', Confidence 0.8300, Bounding Polygon: [(554, 149) (689, 147) (686, 244) (550, 245)]\n",
      "   'Non- Fat milk'\n",
      "   Bounding Polygon: [(149, 302) (633, 297) (633, 374) (150, 378)]\n",
      "     Word: 'Non-', Confidence 0.5770, Bounding Polygon: [(150, 303) (309, 301) (310, 378) (153, 378)]\n",
      "     Word: 'Fat', Confidence 0.8420, Bounding Polygon: [(324, 301) (438, 300) (437, 378) (325, 378)]\n",
      "     Word: 'milk', Confidence 0.9940, Bounding Polygon: [(476, 299) (620, 298) (617, 374) (475, 377)]\n",
      "   'Bread'\n",
      "   Bounding Polygon: [(138, 400) (382, 399) (383, 472) (138, 474)]\n",
      "     Word: 'Bread', Confidence 0.9950, Bounding Polygon: [(152, 400) (366, 400) (368, 471) (151, 475)]\n",
      "   'Eggs'\n",
      "   Bounding Polygon: [(146, 517) (351, 526) (348, 605) (146, 609)]\n",
      "     Word: 'Eggs', Confidence 0.9920, Bounding Polygon: [(149, 517) (342, 519) (341, 610) (148, 609)]\n",
      "\n",
      "Results saved in text.jpg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_text.Main(new string[] { \"2\" });"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "languageName": "csharp",
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
